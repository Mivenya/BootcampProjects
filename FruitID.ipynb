{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mandy's Fruit Identification Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import livelossplot\n",
    "import keras\n",
    "from keras import Sequential\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,ConfusionMatrixDisplay \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install livelossplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting images\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note - the assignment states to divide your dataset here into training and testing, however in this dataset each training and testing already have their own folders for pulling in with a 75% training and 25% testing.\n",
    "\n",
    "## About the dataset\n",
    "The dataset Fruits 360 has a Total number of images: 90483. It has 131 classes (also note there is a multiple fruit set that I haven't used in my modelling at this time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate and assign Training Set - noted that I must switch the slash direction for syntax within paths\n",
    "training_set = train_datagen.flow_from_directory('C:/Users/hyppi/OneDrive/Bootcamp/assessments Python/Module8 - CNN and RNN/fruits-360_dataset/fruits-360/Training',\n",
    "                                                 target_size = (100, 100),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_datagen.flow_from_directory('C:/Users/hyppi/OneDrive/Bootcamp/assessments Python/Module8 - CNN and RNN/fruits-360_dataset/fruits-360/Test',\n",
    "                                            target_size = (100, 100),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical',\n",
    "                                            shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_list = []\n",
    "y_test_list = []\n",
    "batch_index = 0\n",
    "\n",
    "while batch_index <= test_set.batch_index:\n",
    "    x_test,  y_test = test_set.next()\n",
    "    x_test_list.extend(x_test)\n",
    "    y_test_list.extend(y_test)\n",
    "    batch_index = batch_index + 1# now, data_array is the numeric data of whole images\n",
    "  \n",
    "print(x_test_list)\n",
    "print(y_test_list)\n",
    "print(len(x_test_list))\n",
    "print(len(y_test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next to train our model\n",
    "\n",
    "# Initialising the CNN\n",
    "fruit_model = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "fruit_model.add(Conv2D(16, (2, 2), input_shape = (100, 100, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "fruit_model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Another convolutional layer\n",
    "fruit_model.add(Conv2D(32, (2, 2), input_shape = (100, 100, 3), activation = 'relu'))\n",
    "\n",
    "# Another pooling layer with 2x2\n",
    "fruit_model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Two more 2D Convolutional layers with 64 unitix and size 2x2 and relu\n",
    "fruit_model.add(Conv2D(64, (2, 2), input_shape = (100, 100, 3), activation = 'relu'))\n",
    "fruit_model.add(Conv2D(64, (2, 2), input_shape = (100, 100, 3), activation = 'relu'))\n",
    "\n",
    "# Another pooling layer with 2x2\n",
    "fruit_model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Add a dropout layer with 0.3  rate\n",
    "fruit_model.add(Dropout(0.3))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "fruit_model.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection ANN layers\n",
    "# Add fully connected layer with 150 units with ReLU and then a dropout layer with a 0.4 rate\n",
    "fruit_model.add(Dense(units=150, activation='relu'))\n",
    "\n",
    "#another dropout layer with 0.5 rate\n",
    "fruit_model.add(Dropout(rate=0.4))\n",
    "\n",
    "# NOTE - I thought that the output layer was supposed to be the number of classes (131 in this dataset)  however the assignment states to use 81 units - I will inquire on this at next class\n",
    "\n",
    "# Final Output layer fully connected with 81 units and softmax activation.\n",
    "fruit_model.add(Dense(units=131, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the CNN\n",
    "fruit_model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = test_set.class_indices.keys()\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Training to classify fruit\n",
    "\n",
    "### Here I recieved the error ValueError: The `batch_size` argument must not be specified when using a generator or Sequence as an input.\n",
    "\n",
    "###  This led into a different value error saying that the expected size for my dense_2 output layer of 131, was instead showing as a shape of 1, \n",
    "\n",
    "### This led down a bit of a rabbit hole trying to find the solution as essentially it seemed to be binary but our data was catagorical, at first the thought was we might need to one-hot or to_catagorical\n",
    "\n",
    "### In the end however of looking one more time I realized that the example notebook pulled in class_mode of binary and I had missed changing that to categorical, once change it then  worked properly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "fruit_model.fit(training_set,\n",
    "               steps_per_epoch = 32,\n",
    "               epochs = 100,\n",
    "               validation_data=(test_set),\n",
    "               callbacks=[PlotLossesKeras()],\n",
    "               validation_steps = 20,\n",
    "               verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull the loss and accuracy from the model\n",
    "loss, accuracy = fruit_model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Make predictions on the test data with the trained model\n",
    "y_prediction = np.argmax(fruit_model.predict(test_set), axis=1)\n",
    "y_test1 = np.argmax(y_test_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = confusion_matrix(list(y_test1), list(y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(40,40))\n",
    "disp.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The result is showing for me  at 86% accuracy which feels pretty good with 131 classes of fruits and vegetables that might have similar appearance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
